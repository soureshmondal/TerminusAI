{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 438,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0228310502283105,
      "grad_norm": 0.8287496566772461,
      "learning_rate": 0.00019589041095890414,
      "loss": 2.087,
      "step": 10
    },
    {
      "epoch": 0.045662100456621,
      "grad_norm": 0.8580646514892578,
      "learning_rate": 0.000191324200913242,
      "loss": 1.6915,
      "step": 20
    },
    {
      "epoch": 0.0684931506849315,
      "grad_norm": 0.600102961063385,
      "learning_rate": 0.00018675799086757992,
      "loss": 1.6634,
      "step": 30
    },
    {
      "epoch": 0.091324200913242,
      "grad_norm": 0.9911708235740662,
      "learning_rate": 0.00018219178082191782,
      "loss": 1.7009,
      "step": 40
    },
    {
      "epoch": 0.1141552511415525,
      "grad_norm": 0.8337615132331848,
      "learning_rate": 0.00017762557077625574,
      "loss": 1.6336,
      "step": 50
    },
    {
      "epoch": 0.136986301369863,
      "grad_norm": 0.6768602132797241,
      "learning_rate": 0.0001730593607305936,
      "loss": 1.6585,
      "step": 60
    },
    {
      "epoch": 0.1598173515981735,
      "grad_norm": 1.0359184741973877,
      "learning_rate": 0.00016849315068493152,
      "loss": 1.5858,
      "step": 70
    },
    {
      "epoch": 0.182648401826484,
      "grad_norm": 0.6553055047988892,
      "learning_rate": 0.0001639269406392694,
      "loss": 1.5092,
      "step": 80
    },
    {
      "epoch": 0.2054794520547945,
      "grad_norm": 0.8961607813835144,
      "learning_rate": 0.00015936073059360733,
      "loss": 1.6138,
      "step": 90
    },
    {
      "epoch": 0.228310502283105,
      "grad_norm": 0.9018976092338562,
      "learning_rate": 0.0001547945205479452,
      "loss": 1.5045,
      "step": 100
    },
    {
      "epoch": 0.2511415525114155,
      "grad_norm": 0.5586013793945312,
      "learning_rate": 0.00015022831050228312,
      "loss": 1.605,
      "step": 110
    },
    {
      "epoch": 0.273972602739726,
      "grad_norm": 0.5200924277305603,
      "learning_rate": 0.000145662100456621,
      "loss": 1.6503,
      "step": 120
    },
    {
      "epoch": 0.2968036529680365,
      "grad_norm": 0.5471789836883545,
      "learning_rate": 0.00014109589041095893,
      "loss": 1.6121,
      "step": 130
    },
    {
      "epoch": 0.319634703196347,
      "grad_norm": 0.8653632402420044,
      "learning_rate": 0.0001365296803652968,
      "loss": 1.567,
      "step": 140
    },
    {
      "epoch": 0.3424657534246575,
      "grad_norm": 0.6787128448486328,
      "learning_rate": 0.00013196347031963472,
      "loss": 1.5915,
      "step": 150
    },
    {
      "epoch": 0.365296803652968,
      "grad_norm": 0.9952602386474609,
      "learning_rate": 0.0001273972602739726,
      "loss": 1.6339,
      "step": 160
    },
    {
      "epoch": 0.3881278538812785,
      "grad_norm": 0.5656155943870544,
      "learning_rate": 0.00012283105022831053,
      "loss": 1.4481,
      "step": 170
    },
    {
      "epoch": 0.410958904109589,
      "grad_norm": 0.7827343344688416,
      "learning_rate": 0.00011826484018264841,
      "loss": 1.5724,
      "step": 180
    },
    {
      "epoch": 0.4337899543378995,
      "grad_norm": 0.5498148798942566,
      "learning_rate": 0.00011369863013698631,
      "loss": 1.7029,
      "step": 190
    },
    {
      "epoch": 0.45662100456621,
      "grad_norm": 0.4793856739997864,
      "learning_rate": 0.0001091324200913242,
      "loss": 1.5768,
      "step": 200
    },
    {
      "epoch": 0.4794520547945205,
      "grad_norm": 0.5932930111885071,
      "learning_rate": 0.00010456621004566211,
      "loss": 1.6632,
      "step": 210
    },
    {
      "epoch": 0.502283105022831,
      "grad_norm": 0.41730764508247375,
      "learning_rate": 0.0001,
      "loss": 1.5333,
      "step": 220
    },
    {
      "epoch": 0.5251141552511416,
      "grad_norm": 0.6175245046615601,
      "learning_rate": 9.543378995433791e-05,
      "loss": 1.6198,
      "step": 230
    },
    {
      "epoch": 0.547945205479452,
      "grad_norm": 0.6361299157142639,
      "learning_rate": 9.08675799086758e-05,
      "loss": 1.6225,
      "step": 240
    },
    {
      "epoch": 0.5707762557077626,
      "grad_norm": 0.6552761793136597,
      "learning_rate": 8.630136986301371e-05,
      "loss": 1.6625,
      "step": 250
    },
    {
      "epoch": 0.593607305936073,
      "grad_norm": 0.9185230731964111,
      "learning_rate": 8.17351598173516e-05,
      "loss": 1.6016,
      "step": 260
    },
    {
      "epoch": 0.6164383561643836,
      "grad_norm": 0.6611160039901733,
      "learning_rate": 7.716894977168951e-05,
      "loss": 1.5756,
      "step": 270
    },
    {
      "epoch": 0.639269406392694,
      "grad_norm": 0.5522851347923279,
      "learning_rate": 7.26027397260274e-05,
      "loss": 1.5108,
      "step": 280
    },
    {
      "epoch": 0.6621004566210046,
      "grad_norm": 0.6478490829467773,
      "learning_rate": 6.803652968036531e-05,
      "loss": 1.6045,
      "step": 290
    },
    {
      "epoch": 0.684931506849315,
      "grad_norm": 0.7384527921676636,
      "learning_rate": 6.34703196347032e-05,
      "loss": 1.6917,
      "step": 300
    },
    {
      "epoch": 0.7077625570776256,
      "grad_norm": 0.4763428270816803,
      "learning_rate": 5.89041095890411e-05,
      "loss": 1.4672,
      "step": 310
    },
    {
      "epoch": 0.730593607305936,
      "grad_norm": 0.5155137181282043,
      "learning_rate": 5.4337899543379e-05,
      "loss": 1.5724,
      "step": 320
    },
    {
      "epoch": 0.7534246575342466,
      "grad_norm": 0.535706639289856,
      "learning_rate": 4.977168949771689e-05,
      "loss": 1.6773,
      "step": 330
    },
    {
      "epoch": 0.776255707762557,
      "grad_norm": 0.8675767779350281,
      "learning_rate": 4.520547945205479e-05,
      "loss": 1.6286,
      "step": 340
    },
    {
      "epoch": 0.7990867579908676,
      "grad_norm": 0.8085828423500061,
      "learning_rate": 4.063926940639269e-05,
      "loss": 1.5757,
      "step": 350
    },
    {
      "epoch": 0.821917808219178,
      "grad_norm": 0.7409200072288513,
      "learning_rate": 3.60730593607306e-05,
      "loss": 1.5307,
      "step": 360
    },
    {
      "epoch": 0.8447488584474886,
      "grad_norm": 0.5899753570556641,
      "learning_rate": 3.1506849315068496e-05,
      "loss": 1.4914,
      "step": 370
    },
    {
      "epoch": 0.867579908675799,
      "grad_norm": 0.6912678480148315,
      "learning_rate": 2.6940639269406392e-05,
      "loss": 1.6776,
      "step": 380
    },
    {
      "epoch": 0.8904109589041096,
      "grad_norm": 0.7947636246681213,
      "learning_rate": 2.237442922374429e-05,
      "loss": 1.6451,
      "step": 390
    },
    {
      "epoch": 0.91324200913242,
      "grad_norm": 0.5922129154205322,
      "learning_rate": 1.780821917808219e-05,
      "loss": 1.7705,
      "step": 400
    },
    {
      "epoch": 0.9360730593607306,
      "grad_norm": 0.4607854187488556,
      "learning_rate": 1.3242009132420092e-05,
      "loss": 1.5346,
      "step": 410
    },
    {
      "epoch": 0.958904109589041,
      "grad_norm": 0.7172574400901794,
      "learning_rate": 8.675799086757991e-06,
      "loss": 1.5912,
      "step": 420
    },
    {
      "epoch": 0.9817351598173516,
      "grad_norm": 0.4854336977005005,
      "learning_rate": 4.10958904109589e-06,
      "loss": 1.6436,
      "step": 430
    }
  ],
  "logging_steps": 10,
  "max_steps": 438,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1160039028948992e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

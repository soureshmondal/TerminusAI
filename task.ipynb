{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "32ba66acf5b14dbba8bc9befcf6f0723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b47ea1e4fd7f4d18bb20c163913df125",
              "IPY_MODEL_3d0ea65f099b425f95f7307ab6a5b2c8",
              "IPY_MODEL_9ca952dd6b244036881537a9c9e012e2"
            ],
            "layout": "IPY_MODEL_f765d6670ac34ae28b54bc1d16a237b9"
          }
        },
        "b47ea1e4fd7f4d18bb20c163913df125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0252d63fea05458185fa3e4b6405d8f4",
            "placeholder": "​",
            "style": "IPY_MODEL_4275237c32d6433993bdb138eb2bd375",
            "value": "Map: 100%"
          }
        },
        "3d0ea65f099b425f95f7307ab6a5b2c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f051b202697944819accb7a94e38a7d7",
            "max": 1752,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fb34fd61d724b678875b0594196c908",
            "value": 1752
          }
        },
        "9ca952dd6b244036881537a9c9e012e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bca5c6b4e1c4811b5fd136bff3c7750",
            "placeholder": "​",
            "style": "IPY_MODEL_130b1f27082145baafabb396c41f4d71",
            "value": " 1752/1752 [00:01&lt;00:00, 1155.45 examples/s]"
          }
        },
        "f765d6670ac34ae28b54bc1d16a237b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0252d63fea05458185fa3e4b6405d8f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4275237c32d6433993bdb138eb2bd375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f051b202697944819accb7a94e38a7d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb34fd61d724b678875b0594196c908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bca5c6b4e1c4811b5fd136bff3c7750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130b1f27082145baafabb396c41f4d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Collection and Preprocessing"
      ],
      "metadata": {
        "id": "TtkMGRpUTQkb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "msjRUPxETFRz"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data/\n",
        "!cd data/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiD8dq4vTWMH",
        "outputId": "8b9dfea6-2f5d-4b74-9cb0-d2a0534dadcb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##StackOverflow scraper"
      ],
      "metadata": {
        "id": "cfW867W-Tby0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install html2text stackapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhniP65gTY4O",
        "outputId": "0b62a06e-c7a9-431c-a8b2-2234919f25bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting html2text\n",
            "  Downloading html2text-2025.4.15-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting stackapi\n",
            "  Downloading StackAPI-0.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from stackapi) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from stackapi) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->stackapi) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->stackapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->stackapi) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->stackapi) (2025.4.26)\n",
            "Downloading html2text-2025.4.15-py3-none-any.whl (34 kB)\n",
            "Downloading StackAPI-0.3.1-py3-none-any.whl (7.2 kB)\n",
            "Installing collected packages: html2text, stackapi\n",
            "Successfully installed html2text-2025.4.15 stackapi-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "TAGS = [\"git\", \"bash\", \"grep\", \"awk\", \"sed\", \"curl\", \"wget\", \"tar\", \"gzip\",\n",
        "    \"find\", \"chmod\", \"chown\", \"ssh\", \"scp\", \"makefile\", \"docker\", \"apt\",\n",
        "    \"yum\", \"venv\", \"pip\", \"tmux\", \"zsh\", \"crontab\"]\n",
        "OUTPUT_DIR = \"data\"\n",
        "OUTPUT_FILE = \"qa_pairs.json\"\n",
        "MIN_QA_PAIRS = 150\n",
        "API_KEY = \"rl_9yaCcyuncF5mmh3a9WGNiZAAa\"\n",
        "\n",
        "def clean_html(raw_html):\n",
        "    return BeautifulSoup(raw_html, \"html.parser\").get_text().strip()\n",
        "\n",
        "def fetch_top_answer(q_id):\n",
        "    url = f\"https://api.stackexchange.com/2.3/questions/{q_id}/answers\"\n",
        "    params = {\n",
        "        'order': 'desc',\n",
        "        'sort': 'votes',\n",
        "        'site': 'stackoverflow',\n",
        "        'pagesize': 1,\n",
        "        'filter': 'withbody'\n",
        "    }\n",
        "    if API_KEY:\n",
        "        params['key'] = API_KEY\n",
        "\n",
        "    resp = requests.get(url, params=params)\n",
        "    if resp.status_code != 200:\n",
        "        print(f\"  Answer fetch failed: {resp.status_code}\")\n",
        "        return None\n",
        "\n",
        "    answers = resp.json().get(\"items\", [])\n",
        "    if not answers:\n",
        "        return None\n",
        "\n",
        "    return clean_html(answers[0].get(\"body\", \"\"))\n",
        "\n",
        "\n",
        "def fetch_qa(tag, max_pages=4):\n",
        "    qa_pairs = []\n",
        "    for page in range(1, max_pages + 1):\n",
        "        print(f\"Fetching page {page} for tag '{tag}'...\")\n",
        "        url = \"https://api.stackexchange.com/2.3/questions\"\n",
        "        params = {\n",
        "            'order': 'desc',\n",
        "            'sort': 'votes',\n",
        "            'tagged': tag,\n",
        "            'site': 'stackoverflow',\n",
        "            'pagesize': 20,\n",
        "            'page': page,\n",
        "            'filter': 'withbody'\n",
        "        }\n",
        "        if API_KEY:\n",
        "            params['key'] = API_KEY\n",
        "\n",
        "        resp = requests.get(url, params=params)\n",
        "        if resp.status_code != 200:\n",
        "            print(f\"  Error: {resp.status_code} - {resp.text}\")\n",
        "            continue\n",
        "\n",
        "        for q in resp.json().get(\"items\", []):\n",
        "            if not q.get(\"is_answered\"):\n",
        "                continue\n",
        "            q_id = q.get(\"question_id\")\n",
        "            question = clean_html(q.get(\"title\", \"\"))\n",
        "            answer = fetch_top_answer(q_id)\n",
        "            if question and answer:\n",
        "                qa_pairs.append({\n",
        "                    \"question\": question,\n",
        "                    \"answer\": answer,\n",
        "                    \"tag\": tag\n",
        "                })\n",
        "        time.sleep(0.5)\n",
        "    return qa_pairs\n",
        "\n",
        "\n",
        "def main():\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "    all_qa = []\n",
        "    for tag in TAGS:\n",
        "        tag_qa = fetch_qa(tag)\n",
        "        all_qa.extend(tag_qa)\n",
        "        print(f\"Collected {len(tag_qa)} Q&A pairs for '{tag}'\")\n",
        "\n",
        "\n",
        "    print(f\"Total Q&A pairs collected: {len(all_qa)}\")\n",
        "    with open(os.path.join(OUTPUT_DIR, OUTPUT_FILE), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(all_qa, f, indent=2, ensure_ascii=False)\n",
        "    print(\"Saved dataset to\", os.path.join(OUTPUT_DIR, OUTPUT_FILE))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "     main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eow7eGImTgOz",
        "outputId": "dc1e1844-5cfd-4fbb-b915-bb033c3f1cfb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching page 1 for tag 'git'...\n",
            "Fetching page 2 for tag 'git'...\n",
            "Fetching page 3 for tag 'git'...\n",
            "Fetching page 4 for tag 'git'...\n",
            "Collected 80 Q&A pairs for 'git'\n",
            "Fetching page 1 for tag 'bash'...\n",
            "Fetching page 2 for tag 'bash'...\n",
            "Fetching page 3 for tag 'bash'...\n",
            "Fetching page 4 for tag 'bash'...\n",
            "Collected 80 Q&A pairs for 'bash'\n",
            "Fetching page 1 for tag 'grep'...\n",
            "Fetching page 2 for tag 'grep'...\n",
            "Fetching page 3 for tag 'grep'...\n",
            "Fetching page 4 for tag 'grep'...\n",
            "Collected 80 Q&A pairs for 'grep'\n",
            "Fetching page 1 for tag 'awk'...\n",
            "Fetching page 2 for tag 'awk'...\n",
            "Fetching page 3 for tag 'awk'...\n",
            "Fetching page 4 for tag 'awk'...\n",
            "Collected 80 Q&A pairs for 'awk'\n",
            "Fetching page 1 for tag 'sed'...\n",
            "Fetching page 2 for tag 'sed'...\n",
            "Fetching page 3 for tag 'sed'...\n",
            "Fetching page 4 for tag 'sed'...\n",
            "Collected 80 Q&A pairs for 'sed'\n",
            "Fetching page 1 for tag 'curl'...\n",
            "Fetching page 2 for tag 'curl'...\n",
            "Fetching page 3 for tag 'curl'...\n",
            "Fetching page 4 for tag 'curl'...\n",
            "Collected 80 Q&A pairs for 'curl'\n",
            "Fetching page 1 for tag 'wget'...\n",
            "Fetching page 2 for tag 'wget'...\n",
            "Fetching page 3 for tag 'wget'...\n",
            "Fetching page 4 for tag 'wget'...\n",
            "Collected 80 Q&A pairs for 'wget'\n",
            "Fetching page 1 for tag 'tar'...\n",
            "Fetching page 2 for tag 'tar'...\n",
            "Fetching page 3 for tag 'tar'...\n",
            "Fetching page 4 for tag 'tar'...\n",
            "Collected 80 Q&A pairs for 'tar'\n",
            "Fetching page 1 for tag 'gzip'...\n",
            "Fetching page 2 for tag 'gzip'...\n",
            "Fetching page 3 for tag 'gzip'...\n",
            "Fetching page 4 for tag 'gzip'...\n",
            "Collected 80 Q&A pairs for 'gzip'\n",
            "Fetching page 1 for tag 'find'...\n",
            "Fetching page 2 for tag 'find'...\n",
            "Fetching page 3 for tag 'find'...\n",
            "Fetching page 4 for tag 'find'...\n",
            "Collected 80 Q&A pairs for 'find'\n",
            "Fetching page 1 for tag 'chmod'...\n",
            "Fetching page 2 for tag 'chmod'...\n",
            "Fetching page 3 for tag 'chmod'...\n",
            "Fetching page 4 for tag 'chmod'...\n",
            "Collected 80 Q&A pairs for 'chmod'\n",
            "Fetching page 1 for tag 'chown'...\n",
            "Fetching page 2 for tag 'chown'...\n",
            "Fetching page 3 for tag 'chown'...\n",
            "Fetching page 4 for tag 'chown'...\n",
            "Collected 75 Q&A pairs for 'chown'\n",
            "Fetching page 1 for tag 'ssh'...\n",
            "Fetching page 2 for tag 'ssh'...\n",
            "Fetching page 3 for tag 'ssh'...\n",
            "Fetching page 4 for tag 'ssh'...\n",
            "Collected 80 Q&A pairs for 'ssh'\n",
            "Fetching page 1 for tag 'scp'...\n",
            "Fetching page 2 for tag 'scp'...\n",
            "Fetching page 3 for tag 'scp'...\n",
            "Fetching page 4 for tag 'scp'...\n",
            "Collected 80 Q&A pairs for 'scp'\n",
            "Fetching page 1 for tag 'makefile'...\n",
            "Fetching page 2 for tag 'makefile'...\n",
            "Fetching page 3 for tag 'makefile'...\n",
            "Fetching page 4 for tag 'makefile'...\n",
            "Collected 80 Q&A pairs for 'makefile'\n",
            "Fetching page 1 for tag 'docker'...\n",
            "Fetching page 2 for tag 'docker'...\n",
            "Fetching page 3 for tag 'docker'...\n",
            "Fetching page 4 for tag 'docker'...\n",
            "Collected 75 Q&A pairs for 'docker'\n",
            "Fetching page 1 for tag 'apt'...\n",
            "Fetching page 2 for tag 'apt'...\n",
            "Fetching page 3 for tag 'apt'...\n",
            "Fetching page 4 for tag 'apt'...\n",
            "Collected 80 Q&A pairs for 'apt'\n",
            "Fetching page 1 for tag 'yum'...\n",
            "Fetching page 2 for tag 'yum'...\n",
            "Fetching page 3 for tag 'yum'...\n",
            "Fetching page 4 for tag 'yum'...\n",
            "Collected 80 Q&A pairs for 'yum'\n",
            "Fetching page 1 for tag 'venv'...\n",
            "Fetching page 2 for tag 'venv'...\n",
            "Fetching page 3 for tag 'venv'...\n",
            "Fetching page 4 for tag 'venv'...\n",
            "Collected 8 Q&A pairs for 'venv'\n",
            "Fetching page 1 for tag 'pip'...\n",
            "Fetching page 2 for tag 'pip'...\n",
            "Fetching page 3 for tag 'pip'...\n",
            "Fetching page 4 for tag 'pip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-757866262>:16: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
            "\n",
            "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
            "\n",
            "    filehandle = open(your filename)\n",
            "\n",
            "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
            "\n",
            "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
            "\n",
            "    from bs4 import MarkupResemblesLocatorWarning\n",
            "    import warnings\n",
            "\n",
            "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
            "    \n",
            "  return BeautifulSoup(raw_html, \"html.parser\").get_text().strip()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected 80 Q&A pairs for 'pip'\n",
            "Fetching page 1 for tag 'tmux'...\n",
            "Fetching page 2 for tag 'tmux'...\n",
            "Fetching page 3 for tag 'tmux'...\n",
            "Fetching page 4 for tag 'tmux'...\n",
            "Collected 80 Q&A pairs for 'tmux'\n",
            "Fetching page 1 for tag 'zsh'...\n",
            "Fetching page 2 for tag 'zsh'...\n",
            "Fetching page 3 for tag 'zsh'...\n",
            "Fetching page 4 for tag 'zsh'...\n",
            "Collected 80 Q&A pairs for 'zsh'\n",
            "Fetching page 1 for tag 'crontab'...\n",
            "Fetching page 2 for tag 'crontab'...\n",
            "Fetching page 3 for tag 'crontab'...\n",
            "Fetching page 4 for tag 'crontab'...\n",
            "Collected 80 Q&A pairs for 'crontab'\n",
            "Total Q&A pairs collected: 1758\n",
            "Saved dataset to data/qa_pairs.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch transformers peft datasets bitsandbytes accelerate scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LMoMFsTTkhf",
        "outputId": "2731a01a-1688-4954-b732-d2e233eb3eef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLkLzlbzV5xB",
        "outputId": "5fa9b102-bad2-4fe2-d195-e5013f70e357"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trl\n",
            "  Downloading trl-0.18.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.7.0)\n",
            "Collecting datasets>=3.0.0 (from trl)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers>=4.50.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.52.4)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.33.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.0->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.0->trl) (0.21.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (3.0.2)\n",
            "Downloading trl-0.18.2-py3-none-any.whl (366 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.4/366.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets, trl\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0 trl-0.18.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "bKtc2X6G7Pfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "DATASET_PATH = \"data/qa_pairs.json\"\n",
        "OUTPUT_DIR = \"tinyllama_lora_adapter\"\n",
        "MAX_SEQ_LENGTH = 1024\n",
        "\n",
        "def format_instruction(sample):\n",
        "    \"\"\"Format training samples to encourage command-only responses\"\"\"\n",
        "    return (\n",
        "        f\"<|system|>\\nYou are a CLI expert assistant. Generate ONLY step-by-step shell commands without explanations.</s>\\n\"\n",
        "        f\"<|user|>\\n{sample['question']}</s>\\n\"\n",
        "        f\"<|assistant|>\\n{sample['answer']}\\n\"\n",
        "    )\n",
        "\n",
        "def load_and_preprocess_data(file_path):\n",
        "    \"\"\"Load and format dataset with quality filtering\"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "\n",
        "    filtered_data = [\n",
        "        item for item in data\n",
        "        if len(item['answer'].split()) > 3 and not item['answer'].startswith(('Sorry', 'I don\\'t'))\n",
        "    ]\n",
        "\n",
        "    print(f\"Filtered {len(data) - len(filtered_data)} low-quality samples\")\n",
        "    print(f\"Using {len(filtered_data)} samples for training\")\n",
        "\n",
        "\n",
        "    formatted_texts = [format_instruction(item) for item in filtered_data]\n",
        "\n",
        "    return {\"text\": formatted_texts}\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\" if device == \"cuda\" else None,\n",
        "    torch_dtype=torch.float32\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# Prepare dataset\n",
        "dataset_dict = load_and_preprocess_data(DATASET_PATH)\n",
        "dataset = Dataset.from_dict(dataset_dict)\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=MAX_SEQ_LENGTH,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"v_proj\"]\n",
        ")\n",
        "\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    optim=\"adamw_torch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\",\n",
        "    max_grad_norm=0.3\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "model.save_pretrained(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "print(f\"Adapter saved to {OUTPUT_DIR}\")\n",
        "\n",
        "\n",
        "test_prompt = (\n",
        "    \"<|system|>\\nYou are a CLI expert assistant. Generate step-by-step shell commands.</s>\\n\"\n",
        "    \"<|user|>\\nHow to find all .log files modified in last 7 days?</s>\\n\"\n",
        "    \"<|assistant|>\\n\"\n",
        ")\n",
        "\n",
        "inputs = tokenizer(test_prompt, return_tensors=\"pt\", return_attention_mask=False).to(device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=128,\n",
        "    temperature=0.3,\n",
        "    do_sample=True,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.1\n",
        ")\n",
        "\n",
        "print(\"\\n\\nGenerated output:\\n\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "32ba66acf5b14dbba8bc9befcf6f0723",
            "b47ea1e4fd7f4d18bb20c163913df125",
            "3d0ea65f099b425f95f7307ab6a5b2c8",
            "9ca952dd6b244036881537a9c9e012e2",
            "f765d6670ac34ae28b54bc1d16a237b9",
            "0252d63fea05458185fa3e4b6405d8f4",
            "4275237c32d6433993bdb138eb2bd375",
            "f051b202697944819accb7a94e38a7d7",
            "6fb34fd61d724b678875b0594196c908",
            "0bca5c6b4e1c4811b5fd136bff3c7750",
            "130b1f27082145baafabb396c41f4d71"
          ]
        },
        "id": "Z8z_ihCbWStp",
        "outputId": "d46e2c10-748a-43e6-ecac-fb5b6042be2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Filtered 6 low-quality samples\n",
            "Using 1752 samples for training\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1752 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32ba66acf5b14dbba8bc9befcf6f0723"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,252,800 || all params: 1,102,301,184 || trainable%: 0.2044\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='438' max='438' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [438/438 41:59, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.087000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.691500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.663400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.700900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.633600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.658500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.585800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.509200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.613800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.504500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.605000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.650300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.612100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.567000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.591500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.633900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.448100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.572400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.702900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.576800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.663200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.533300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.619800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.622500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.662500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.601600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.575600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.510800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>1.604500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.691700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>1.467200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.572400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>1.677300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.628600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.575700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.530700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>1.491400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.677600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>1.645100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.770500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>1.534600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>1.591200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>1.643600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapter saved to tinyllama_lora_adapter\n",
            "\n",
            "\n",
            "Generated output:\n",
            " <|system|>\n",
            "You are a CLI expert assistant. Generate step-by-step shell commands. \n",
            "<|user|>\n",
            "How to find all .log files modified in last 7 days? \n",
            "<|assistant|>\n",
            "find . -type f -mtime +7 -print0 | xargs -0 tail -n 1\n",
            "\n",
            "This will give you the first log file that was modified within the last 7 days. If you want to get the last modified date, use:\n",
            "find . -type f -mtime +7 -exec ls -l {} \\; | awk '{print $6}'\n",
            "\n",
            "If you want to get the last modified time of each file, then use:\n",
            "find . -type f -mtime +7 -exec ls -lt {} \\; | awk '{print $9}'\n",
            "\n",
            "The -exec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zijWJoRtgXo3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}